{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e3b311",
   "metadata": {},
   "source": [
    "## Exercise VAEs\n",
    "\n",
    "You need to install `torch` and `torchvision` to run the code in this notebook. You can do this via conda or pip:\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision\n",
    "```\n",
    "or\n",
    "```bash\n",
    "conda install pytorch torchvision -c pytorch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68377f7f",
   "metadata": {},
   "source": [
    "Import the necessary libraries and download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 15\n",
    "LATENT_DIM = 2  # We use 2 dimensions to easily visualize the latent space later\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Data Loading (MNIST)\n",
    "transform = transforms.ToTensor() # Normalizes to [0, 1]\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0605c",
   "metadata": {},
   "source": [
    "Define the VAE model, the training loop, and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353dfa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # --- Encoder ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # We output two vectors: mean (mu) and log-variance (log_var)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # --- Decoder ---\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc_mu(h1), self.fc_logvar(h1)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        THE REPARAMETERIZATION TRICK\n",
    "        z = mu + sigma * epsilon\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar) # convert log_var to standard deviation\n",
    "            eps = torch.randn_like(std)   # sample epsilon from standard normal\n",
    "            return mu + eps * std\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3)) # Sigmoid because pixels are [0, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "model = VAE(latent_dim=LATENT_DIM).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # 1. Reconstruction Loss (Binary Cross Entropy)\n",
    "    # reduction='sum' sums over the batch. We want the total loss.\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # 2. KL Divergence\n",
    "    # Analytical solution for KL(q(z|x) || N(0,1))\n",
    "    # Formula: -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)}] Loss: {loss.item()/len(data):.4f}')\n",
    "\n",
    "    print(f'====> Epoch {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')\n",
    "\n",
    "# Run training\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, _ = next(iter(test_loader))\n",
    "        data = data.to(DEVICE)\n",
    "        recon, _, _ = model(data)\n",
    "        \n",
    "        # TODO: Visualize original and reconstructed images\n",
    "\n",
    "visualize_reconstruction()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
